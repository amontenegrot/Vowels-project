{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_AMT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-3RLeG_aZMpB"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNNnQ0UqoHGu7iFXegVEGce",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amontenegrot/Vowels-project/blob/main/CNN_AMT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ros4o0eDBOC"
      },
      "source": [
        "#Permisos y Librerias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1KorAeRfCju"
      },
      "source": [
        "Permisos e instalación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TGPjqitfJKO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26a2eaf5-4a0b-4ca1-c60b-085d6676a029"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6I375L2fBT4"
      },
      "source": [
        "##Librerias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8ofY0ZUlt-X"
      },
      "source": [
        "import os,cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras import backend as K\n",
        "#K.set_image_dim_ordering('th')\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.layers.convolutional import Conv2D #Solució de error en el nuevo keras\n",
        "from keras.optimizers import SGD,RMSprop"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CHmkKgQMLhA"
      },
      "source": [
        "from PIL import Image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.offline as py\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.figure_factory as ff"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyyemK_Pe_PP"
      },
      "source": [
        "Funciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FiqN8oRFZLM"
      },
      "source": [
        "def extractor_nombres(ruta):\n",
        "  lista = []\n",
        "\n",
        "  for dirName, subdirList, fileList in os.walk(ruta):\n",
        "    for fname in fileList:\n",
        "        lista.append(fname) #Añadir el nombre del archivo a la lista\n",
        "  return lista"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOhPPId5CqfJ"
      },
      "source": [
        "#Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3qeoJZJi9nm"
      },
      "source": [
        "##Lectura de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qcn0z5ujOD8i"
      },
      "source": [
        "#Ruta de lectura\n",
        "PATH_ROOT = '/content/drive/My Drive/Proyectos/Machine learning/CNN Espectrogramas/Datos/Prueba de concepto/Imágenes raw/'\n",
        "\n",
        "#Carpetas de entrenamiento\n",
        "TRAIN = PATH_ROOT + 'Train/'\n",
        "TEST = PATH_ROOT + 'Test/'\n",
        "\n",
        "#Vocales de entrenamiento \n",
        "TRAIN_VOWELS_I = TRAIN + 'i/'\n",
        "TRAIN_VOWELS_E = TRAIN + 'e/'\n",
        "TRAIN_VOWELS_A = TRAIN + 'a/'\n",
        "TRAIN_VOWELS_O = TRAIN + 'o/'\n",
        "TRAIN_VOWELS_U = TRAIN + 'u/'\n",
        "\n",
        "#Vocales de prueba\n",
        "TEST_VOWELS_I = TEST + 'i/'\n",
        "TEST_VOWELS_E = TEST + 'e/'\n",
        "TEST_VOWELS_A = TEST + 'a/'\n",
        "TEST_VOWELS_O = TEST + 'o/'\n",
        "TEST_VOWELS_U = TEST + 'u/'\n",
        "\n",
        "#Ruta de salida\n",
        "PATH_OUT = '/content/drive/My Drive/Proyectos/Machine learning/CNN Espectrogramas/Datos/Prueba de concepto/Alejandro/'"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtGDysYWFUtW"
      },
      "source": [
        "#Declaración de listas con archivos\n",
        "ies_train = ees_train = aes_train = oes_train = ues_train = []\n",
        "ies_test = ees_test = aes_test = oes_test = ues_test = []"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZzibLCSdluh"
      },
      "source": [
        "ies_train = extractor_nombres(TRAIN_VOWELS_I)\n",
        "ees_train = extractor_nombres(TRAIN_VOWELS_E)\n",
        "aes_train = extractor_nombres(TRAIN_VOWELS_A)\n",
        "oes_train = extractor_nombres(TRAIN_VOWELS_O)\n",
        "ues_train = extractor_nombres(TRAIN_VOWELS_U)\n",
        "\n",
        "ies_test = extractor_nombres(TEST_VOWELS_I)\n",
        "ees_test = extractor_nombres(TEST_VOWELS_E)\n",
        "aes_test = extractor_nombres(TEST_VOWELS_A)\n",
        "oes_test = extractor_nombres(TEST_VOWELS_O)\n",
        "ues_test = extractor_nombres(TEST_VOWELS_U)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3RLeG_aZMpB"
      },
      "source": [
        "##Reporte de datos\n",
        "\n",
        "Conociendo el número de vocales que servirán para alimentar la *red neuronal artificial convolucional*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR1dDbu3IEBk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdeff0fb-153e-4831-b65b-ea5144d3b2a0"
      },
      "source": [
        "print('Total de archivos a procesar según la vocal (entrenamiento):', '\\n')\n",
        "print('\\t', '/i/:', len(ies_train), 'elementos')\n",
        "print('\\t', '/e/:', len(ees_train), 'elementos')\n",
        "print('\\t', '/a/:', len(aes_train), 'elementos')\n",
        "print('\\t', '/o/:', len(oes_train), 'elementos')\n",
        "print('\\t', '/u/:', len(ues_train), 'elementos', '\\n')\n",
        "print('Total de archivos:', \n",
        "      len(ies_train)+len(ees_train)+len(aes_train)+len(oes_train)+len(ues_train), \n",
        "      'elementos')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total de archivos a procesar según la vocal (entrenamiento): \n",
            "\n",
            "\t /i/: 145 elementos\n",
            "\t /e/: 189 elementos\n",
            "\t /a/: 224 elementos\n",
            "\t /o/: 157 elementos\n",
            "\t /u/: 133 elementos \n",
            "\n",
            "Total de archivos: 848 elementos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZvGluFeKvsY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4242154-1835-44cb-d734-e5bd10a8adc7"
      },
      "source": [
        "print('Total de archivos a procesar según la vocal (pruebas):', '\\n')\n",
        "print('\\t', '/i/:', len(ies_test), 'elementos')\n",
        "print('\\t', '/e/:', len(ees_test), 'elementos')\n",
        "print('\\t', '/a/:', len(aes_test), 'elementos')\n",
        "print('\\t', '/o/:', len(oes_test), 'elementos')\n",
        "print('\\t', '/u/:', len(ues_test), 'elementos', '\\n')\n",
        "print('Total de archivos:', \n",
        "      len(ies_test)+len(ees_test)+len(aes_test)+len(oes_test)+len(ues_test), \n",
        "      'elementos')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total de archivos a procesar según la vocal (pruebas): \n",
            "\n",
            "\t /i/: 61 elementos\n",
            "\t /e/: 80 elementos\n",
            "\t /a/: 95 elementos\n",
            "\t /o/: 67 elementos\n",
            "\t /u/: 56 elementos \n",
            "\n",
            "Total de archivos: 359 elementos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrTfnOvtHUO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fffb628-f0d0-4da8-c16b-2939684c4acf"
      },
      "source": [
        "print('Total de archivos a procesar según la vocal:', '\\n')\n",
        "print('\\t', '/i/:', len(ies_train)+len(ies_test), 'elementos')\n",
        "print('\\t', '/e/:', len(ees_train)+len(ees_test), 'elementos')\n",
        "print('\\t', '/a/:', len(aes_train)+len(aes_test), 'elementos')\n",
        "print('\\t', '/o/:', len(oes_train)+len(oes_test), 'elementos')\n",
        "print('\\t', '/u/:', len(ues_test)+len(ues_test), 'elementos', '\\n')\n",
        "print('Total de archivos:',\n",
        "      len(ies_test)+len(ees_test)+len(aes_test)+len(oes_test)+len(ues_test)+\n",
        "      len(ies_train)+len(ees_train)+len(aes_train)+len(oes_train)+len(ues_train),\n",
        "      'elementos')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total de archivos a procesar según la vocal: \n",
            "\n",
            "\t /i/: 206 elementos\n",
            "\t /e/: 269 elementos\n",
            "\t /a/: 319 elementos\n",
            "\t /o/: 224 elementos\n",
            "\t /u/: 112 elementos \n",
            "\n",
            "Total de archivos: 1207 elementos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4FTiGc6i0NZ"
      },
      "source": [
        "##Carga de datos\n",
        "\n",
        "Información en esta [página web](https://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3MofsIL4eBO"
      },
      "source": [
        "#Declaración de variables\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "WIDTH_SIZE = 124  # Ancho en pixeles de la imagen\n",
        "HEIGHT_SIZE = 734  # Alto en pixeles de la imagen"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDxiGhEcjHT8"
      },
      "source": [
        "#Crear el generador de datos\n",
        "datagen_train = ImageDataGenerator(rescale=1.0/255)\n",
        "datagen_test = ImageDataGenerator(rescale=1.0/255)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHipXwFWuxy4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58679131-f6b4-4f5b-9e0f-c6d273926ed9"
      },
      "source": [
        "#Iterar generador en el conjunto de datos\n",
        "train_data = datagen_train.flow_from_directory(TRAIN, class_mode='categorical',\n",
        "                                         batch_size=batch_size,\n",
        "                                         target_size=(HEIGHT_SIZE, WIDTH_SIZE))\n",
        "\n",
        "test_data = datagen_test.flow_from_directory(TEST, class_mode='categorical',\n",
        "                                        batch_size = batch_size,\n",
        "                                        target_size=(HEIGHT_SIZE, WIDTH_SIZE))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 848 images belonging to 5 classes.\n",
            "Found 359 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cikyiMyS8Lz"
      },
      "source": [
        "#Preprocesamiento de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPxwpI80c5l4"
      },
      "source": [
        "##Formato *one-hot*\n",
        "\n",
        "Más información en esta [página web](https://www.interactivechaos.com/python/scenario/codificacion-one-hot-encoding-de-un-conjunto-de-caracteristicas-categoricas-con)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzsqiE5hb-S9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbca76ba-500a-4102-85fc-fdfcf8baf448"
      },
      "source": [
        "vowels_output = ['i', 'e', 'a', 'o', 'u']\n",
        "\n",
        "ohe = OneHotEncoder(sparse = False)\n",
        "le = LabelEncoder()\n",
        "\n",
        "vowels_one_hot = ohe.fit_transform(le.fit_transform(vowels_output).reshape(-1, 1))\n",
        "nclases = 5\n",
        "\n",
        "vowels_one_hot"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vJsu4-xCq6p"
      },
      "source": [
        "#Red Neuronal Artificial Convolucional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7sZB6SiTt6Y"
      },
      "source": [
        "##Creación del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyiiFKl-TFUp"
      },
      "source": [
        "# Contenedor del modelo\n",
        "modelo = Sequential()"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKwqz8L-TXVU"
      },
      "source": [
        "# CONV1 Y MAX-POOLING1\n",
        "modelo.add(Conv2D(filters=6, kernel_size=(3,3), activation='relu', input_shape=(WIDTH_SIZE,HEIGHT_SIZE,3)))  # Ancho, alto, color (canales)\n",
        "modelo.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# CONV2 Y MAX-POOLING2\n",
        "modelo.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu'))\n",
        "modelo.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Aplanar, FC1, FC2 y salida\n",
        "modelo.add(Flatten())\n",
        "modelo.add(Dense(120,activation='relu'))\n",
        "modelo.add(Dense(84,activation='relu'))\n",
        "modelo.add(Dense(nclases,activation='softmax'))"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTLQdP4yTw5Q"
      },
      "source": [
        "##Compilación del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cagsfp4ZTzGg"
      },
      "source": [
        "# Optimizador a usar (gradiente descendente, tasa de aprendizaje = 0.1)\n",
        "modelo.compile(loss='categorical_crossentropy', \n",
        "               optimizer='adam',\n",
        "               metrics=['accuracy'])"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27qW0ynzwnUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3414136-a197-4a4f-b155-14a9dff976c2"
      },
      "source": [
        "modelo.summary()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 122, 732, 6)       168       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 61, 366, 6)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 59, 364, 16)       880       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 29, 182, 16)       0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 84448)             0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 120)               10133880  \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 5)                 425       \n",
            "=================================================================\n",
            "Total params: 10,145,517\n",
            "Trainable params: 10,145,517\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bqwz8vfvVWEb"
      },
      "source": [
        "##Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r7-YmyJuB5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4ec3b4a-19a1-4463-c7e3-28c5d4931c6e"
      },
      "source": [
        "modelo.fit(train_data,\n",
        "           epochs=10, \n",
        "           validation_data=test_data)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "85/85 [==============================] - 8s 88ms/step - loss: 2.0187 - accuracy: 0.4390 - val_loss: 0.7847 - val_accuracy: 0.6825\n",
            "Epoch 2/10\n",
            "85/85 [==============================] - 7s 86ms/step - loss: 0.6588 - accuracy: 0.7527 - val_loss: 0.8389 - val_accuracy: 0.6435\n",
            "Epoch 3/10\n",
            "85/85 [==============================] - 7s 85ms/step - loss: 0.4970 - accuracy: 0.8167 - val_loss: 0.7735 - val_accuracy: 0.6880\n",
            "Epoch 4/10\n",
            "85/85 [==============================] - 7s 85ms/step - loss: 0.3157 - accuracy: 0.8857 - val_loss: 0.8400 - val_accuracy: 0.7019\n",
            "Epoch 5/10\n",
            "85/85 [==============================] - 7s 87ms/step - loss: 0.1556 - accuracy: 0.9455 - val_loss: 1.0268 - val_accuracy: 0.6880\n",
            "Epoch 6/10\n",
            "85/85 [==============================] - 7s 86ms/step - loss: 0.0679 - accuracy: 0.9856 - val_loss: 1.0555 - val_accuracy: 0.7103\n",
            "Epoch 7/10\n",
            "85/85 [==============================] - 7s 85ms/step - loss: 0.0850 - accuracy: 0.9685 - val_loss: 1.3665 - val_accuracy: 0.6936\n",
            "Epoch 8/10\n",
            "85/85 [==============================] - 7s 84ms/step - loss: 0.0330 - accuracy: 0.9914 - val_loss: 1.3225 - val_accuracy: 0.6880\n",
            "Epoch 9/10\n",
            "85/85 [==============================] - 7s 86ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.3240 - val_accuracy: 0.7326\n",
            "Epoch 10/10\n",
            "85/85 [==============================] - 7s 86ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3261 - val_accuracy: 0.7409\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5e7028dc88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be-bYCKBC7IS"
      },
      "source": [
        "#Validación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmv8RX1xCqLo"
      },
      "source": [
        ""
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU_4aV6W0bgS"
      },
      "source": [
        "#Miscelanea\n",
        "\n",
        "Guía conceptual: [*LeNet-5*](https://github.com/codificandobits/Clasificacion_MNIST_RedesConvolucionales_Keras/blob/master/Clasificacion_de_Digitos_Usando_Redes_Convolucionales_y_Keras.ipynb)\n",
        "\n",
        "[Colab SL](https://colab.research.google.com/drive/1BXjv9gLsVj673dDUupsexyj010A19Y3E?usp=sharing)\n",
        "\n",
        "[Colab NS](https://colab.research.google.com/drive/1QToJzgwbFXdzSuqXMDoH26Ph3USGgW2T?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMZm2Vjenjtr"
      },
      "source": [
        "[Tutorial](https://medium.com/@hewani.co/building-a-simple-convolutional-neural-net-with-own-data-c0ee8654bacb)\n",
        "\n",
        "[Git-hub tuto](https://github.com/rickmunene/simple-cnn-with-own-data/blob/master/Simple%20Convolutional%20Neural%20Net%20With%20Own%20Data.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d45nswQJtByX"
      },
      "source": [
        "[Tutorial en Colab bien explicado](https://colab.research.google.com/drive/1a7V9Hc7ks0xxDbfCZl2_96DUGlCLuh00)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbdKq9eB_6SA"
      },
      "source": [
        "Ayudas comentadas por Néstor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBMOQI-I_-6M"
      },
      "source": [
        "[Tensor board](https://www.tensorflow.org/tensorboard?hl=es-419)\n",
        "\n",
        "[TensorFlow Hub](https://www.tensorflow.org/hub?hl=es-419)\n",
        "\n",
        "[Introducción al deep learning](https://www.udacity.com/course/deep-learning-pytorch--ud188)"
      ]
    }
  ]
}